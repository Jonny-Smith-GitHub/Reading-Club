# 统计学习方法

## 第一章 统计学习方法概论

### 一、问题讨论

#### (1) 自己的问题

1. 为什么生成方法较判别方法更快收敛于真实模型?

判别方法会对数据进行各种程度的抽象,而不是直接面向概率分布.

1. 为什么当存在隐变量时,仍可用生成方法却不能用判别方法? 

隐变量的存在使得模型需要建模隐变量本身的分布情况以及隐变量和其他变量的关系, 而判别模型是直接建模最终需要的决策函数或者条件概率分布，没有将隐变量纳入其中。

#### (2) 他人的问题

1. 测试误差一定会随着复杂度的增加而先减小后增大吗？

在大多数情况是。因为随着模型复杂度的增加，模型拟合能力随之增强，对结果的预测能力也会更强。但是很有可能拟合“过度”，从而对数据扰动更加敏感，方差增大。从模型评价上来看，模型复杂度增加后，验证集效果提升，测试集效果下降的现象。

2. 4种损失函数如何选择？

考虑离群点情况，即一个点与它的预测值差值非常大。一般来说，我们可以将（1）0-1损失函数分为一类，若选用该方法，则离群点则仅仅表示一个数据被损坏的点。（2）（3）（4）分为一类，对离群点的值异常敏感。（2）（3）（4）方法差别不大，在曲线平滑程度、迭代次数上有细微差异

3. 如何理解“可以假设复杂模型有较小的先验概率，简单模型有较大的先验概率” ?

复杂模型对变量之间的关系做出了许多设定，相比于简单模型，总的来说天然地难以满足，也就是先验概率低。

4. 如何减少过拟合？

获取额外数据进行交叉验证。或者正则化，即在进行目标函数或代价函数优化时，在目标函数或代价函数后面加上一个正则项，一般有L1正则与L2正则等。

### 二、内容摘要

(1) 统计学习分类:

1. **监督学习(supervised learning)**
2. 非监督学习(unsupervised learning)
3. 半监督学习(semi-supervised learning)
4. 强化学习(reinforcement learning)

(2) 实现统计学习方法的步骤:

1. 得到一个有限的训练数据集合
2. **确定包含所有可能模型的假设空间(模型)**
3. **确定模型选择的准则(策略)**
4. **实现求解最优模型的算法(算法)**
5. 通过学习方法选择最优模型
6. 利用最优模型对新数据进行预测分析

(3) 监督学习概念:

1. 输入空间→特征空间→模型→输出空间
2. 回归问题, 分类问题, 标注问题
3. **输入与输出变量遵循某一联合概率分布(监督学习关于数据的基本假设)**

(4)策略:

1. 损失函数与风险函数
2. 经验风险最小化与结构风险最小化

(4) 交叉验证

1. 简单交叉验证
2. S折交叉验证
3. 留一交叉验证

(5)泛化

**定理1.1(泛化误差上界)**: 

对于二分类问题, 下述式子成立:
$$
Pr(R(f)≤\hat R(f)+\varepsilon(d,N,\sigma))≥1-\sigma
$$
其中: d为假设空间大小, N为测试用例数量.

(5)生成模型与判别模型

1. 生成方法:

$$
P(Y|X)=\frac{P(X,Y)}{P(X)}
$$

典型的生成模型: 朴素贝叶斯, 隐马尔可夫模型

2. 判别方法:

直接学习决策函数$f(X)$, 或者条件概率分布作为预测模型.

典型的判别模型: k近邻法, 感知机, 决策树, 逻辑斯谛回归模型,最大熵模型, 支持向量机, 生成方法和条件随机场......

(6) 分类问题

评价指标: 准确率(accuracy),精确率(precision)与召回率(recall)

(7)标注问题

$(x_1,x_2,...,x_m)→(y_1,y_2,...,y_n)$

(8)回归问题

函数拟合

### 三、程序实现

~~~~python
#Date:2020/12/16	Authour:陆星宇
#本次无
~~~~



### 四、下周计划

阅读《统计学习方法》第二章